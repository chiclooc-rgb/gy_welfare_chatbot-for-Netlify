#!/usr/bin/env python3
# simple_ingest.py - ê°„ë‹¨í•œ ë²„ì „ì˜ ì¸ë±ì‹± ìŠ¤í¬ë¦½íŠ¸

import os
import json
import re
import glob
from pathlib import Path

DATA_DIR = Path("data")
INDEX_DIR = Path("index")
INDEX_DIR.mkdir(exist_ok=True)

CHUNK_SIZE = 1000
CHUNK_OVERLAP = 200

def read_txt(path: Path) -> str:
    """í…ìŠ¤íŠ¸ íŒŒì¼ ì½ê¸°"""
    try:
        return path.read_text(encoding="utf-8", errors="ignore")
    except Exception as e:
        print(f"í…ìŠ¤íŠ¸ íŒŒì¼ ì½ê¸° ì‹¤íŒ¨ {path}: {e}")
        return ""

def read_md(path: Path) -> str:
    """ë§ˆí¬ë‹¤ìš´ íŒŒì¼ ì½ê¸°"""
    try:
        raw = path.read_text(encoding="utf-8", errors="ignore")
        # ê°„ë‹¨í•œ ë§ˆí¬ë‹¤ìš´ ì²˜ë¦¬ (BeautifulSoup ì—†ì´)
        text = re.sub(r'#+ ', '', raw)  # í—¤ë” ì œê±°
        text = re.sub(r'\*\*(.*?)\*\*', r'\1', text)  # ë³¼ë“œ ì œê±°
        text = re.sub(r'\*(.*?)\*', r'\1', text)  # ì´íƒ¤ë¦­ ì œê±°
        text = re.sub(r'`(.*?)`', r'\1', text)  # ì½”ë“œ ì œê±°
        return text
    except Exception as e:
        print(f"ë§ˆí¬ë‹¤ìš´ íŒŒì¼ ì½ê¸° ì‹¤íŒ¨ {path}: {e}")
        return ""

def load_and_extract(path: Path) -> str:
    """íŒŒì¼ í™•ì¥ìì— ë”°ë¼ ì ì ˆí•œ íŒŒì„œë¡œ í…ìŠ¤íŠ¸ ì¶”ì¶œ"""
    ext = path.suffix.lower()
    if ext == ".txt":
        return read_txt(path)
    elif ext == ".md":
        return read_md(path)
    else:
        print(f"ì§€ì›í•˜ì§€ ì•ŠëŠ” íŒŒì¼ í˜•ì‹: {ext}")
        return ""

def chunk_text(text: str, size=CHUNK_SIZE, overlap=CHUNK_OVERLAP):
    """í…ìŠ¤íŠ¸ë¥¼ ì²­í¬ ë‹¨ìœ„ë¡œ ë¶„í• """
    text = re.sub(r"\n{3,}", "\n\n", text).strip()
    chunks = []
    start = 0
    while start < len(text):
        end = start + size
        chunk = text[start:end]
        chunks.append(chunk)
        if end >= len(text):
            break
        start = end - overlap
    return chunks

def main():
    """ë©”ì¸ ì¸ë±ì‹± íŒŒì´í”„ë¼ì¸ (ê°„ë‹¨í•œ ë²„ì „)"""
    print("=== ê°„ë‹¨í•œ ë¬¸ì„œ ì¸ë±ì‹± ì‹œì‘ ===")
    
    # ì§€ì›í•˜ëŠ” íŒŒì¼ í˜•ì‹ë“¤ ìˆ˜ì§‘
    files = []
    for ext in ("*.txt", "*.md"):
        files.extend(glob.glob(str(DATA_DIR / ext)))
    files = [Path(f) for f in files]
    
    if not files:
        print(f"âŒ {DATA_DIR} ë””ë ‰í„°ë¦¬ì— ì§€ì›í•˜ëŠ” íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤.")
        print("ì§€ì› í˜•ì‹: .txt, .md")
        return

    print(f"ğŸ“ ë°œê²¬ëœ íŒŒì¼: {len(files)}ê°œ")
    for f in files:
        print(f"  - {f.name}")

    metadatas = []
    corpus_texts = []

    uid = 0
    for i, f in enumerate(files):
        print(f"íŒŒì‹± ì¤‘... ({i+1}/{len(files)}) {f.name}")
        text = load_and_extract(f)
        if not text: 
            print(f"âš ï¸  {f.name}: í…ìŠ¤íŠ¸ ì¶”ì¶œ ì‹¤íŒ¨")
            continue
            
        chunks = chunk_text(text)
        print(f"ğŸ“„ {f.name}: {len(chunks)}ê°œ ì²­í¬ ìƒì„±")
        
        for j, ch in enumerate(chunks):
            meta = {
                "uid": uid,
                "source": f.name,
                "chunk_id": j,
                "path": str(f.resolve())
            }
            corpus_texts.append(ch)
            metadatas.append(meta)
            uid += 1

    print(f"âœ… ì´ ì²­í¬ ìˆ˜: {len(corpus_texts)}")
    if not corpus_texts:
        print("âŒ ì²­í¬ê°€ ìƒì„±ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
        return

    # ê°„ë‹¨í•œ ë©”íƒ€ë°ì´í„°ë§Œ ì €ì¥ (ì„ë² ë”© ì—†ì´)
    with open(INDEX_DIR / "simple_meta.json", "w", encoding="utf-8") as f:
        json.dump({"metas": metadatas, "texts": corpus_texts}, f, ensure_ascii=False)

    print("âœ… ì™„ë£Œ! ê°„ë‹¨í•œ ë©”íƒ€ë°ì´í„°ê°€ ./index/simple_meta.jsonì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")
    print(f"ğŸ“Š í†µê³„:")
    print(f"  - ì´ ë¬¸ì„œ: {len(files)}ê°œ")
    print(f"  - ì´ ì²­í¬: {len(corpus_texts)}ê°œ")

if __name__ == "__main__":
    main()

