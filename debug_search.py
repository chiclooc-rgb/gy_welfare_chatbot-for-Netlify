#!/usr/bin/env python3
# debug_search.py - Search functionality test

import json
from pathlib import Path

def load_documents():
    """ë¬¸ì„œ ë¡œë“œ í…ŒìŠ¤íŠ¸"""
    index_dir = Path("index")
    try:
        with open(index_dir / "simple_meta.json", "r", encoding="utf-8") as f:
            store = json.load(f)
        metas = store["metas"]
        texts = store["texts"]
        print(f"âœ… ë¬¸ì„œ ë¡œë“œ ì™„ë£Œ: {len(texts)}ê°œ ì²­í¬")
        
        # ì²« 5ê°œ í…ìŠ¤íŠ¸ ìƒ˜í”Œ ì¶œë ¥
        print("\nğŸ“„ ì²« 5ê°œ í…ìŠ¤íŠ¸ ìƒ˜í”Œ:")
        for i, text in enumerate(texts[:5]):
            print(f"{i+1}. {text[:100]}...")
            
        # ë‹¤ìë…€ ê´€ë ¨ ê²€ìƒ‰ í…ŒìŠ¤íŠ¸
        print("\nğŸ” 'ë‹¤ìë…€' ê²€ìƒ‰ í…ŒìŠ¤íŠ¸:")
        found_count = 0
        for i, text in enumerate(texts):
            if "ë‹¤ìë…€" in text.lower():
                print(f"  ë°œê²¬ {i+1}: {text[:200]}...")
                found_count += 1
        print(f"ì´ {found_count}ê°œ ì²­í¬ì—ì„œ 'ë‹¤ìë…€' ë°œê²¬")
        
        # ìë…€ ê´€ë ¨ ê²€ìƒ‰ í…ŒìŠ¤íŠ¸
        print("\nğŸ” 'ìë…€' ê²€ìƒ‰ í…ŒìŠ¤íŠ¸:")
        found_count = 0
        for i, text in enumerate(texts):
            if "ìë…€" in text.lower():
                print(f"  ë°œê²¬ {i+1}: {text[:200]}...")
                found_count += 1
                if found_count >= 3:  # ì²˜ìŒ 3ê°œë§Œ ì¶œë ¥
                    break
        print(f"ì´ {found_count}ê°œ ì²­í¬ì—ì„œ 'ìë…€' ë°œê²¬")
        
        return texts, metas
        
    except Exception as e:
        print(f"âŒ ë¬¸ì„œ ë¡œë“œ ì‹¤íŒ¨: {e}")
        return [], []

def expand_query(query):
    """ì¿¼ë¦¬ í™•ì¥ í…ŒìŠ¤íŠ¸"""
    KEYWORD_EXPANSION = {
        "ë‹¤ìë…€ê°€ì •": ["ë‹¤ìë…€", "ì…‹ì§¸ì•„ì´", "3ìë…€", "3ëª… ì´ìƒ", "ë§ì€ ìë…€", "ìë…€ 3ëª…", "ì„¸ ìë…€"],
        "ë‹¤ìë…€": ["ë‹¤ìë…€ê°€ì •", "ì…‹ì§¸ì•„ì´", "3ìë…€", "3ëª… ì´ìƒ", "ë§ì€ ìë…€"],
        "í˜œíƒ": ["ì§€ì›", "ë³´ì¡°", "ê¸‰ì—¬", "ìˆ˜ë‹¹", "í• ì¸", "ê°ë©´", "ìš°ëŒ€", "ë°”ìš°ì²˜"],
        "ì§€ì›": ["í˜œíƒ", "ë³´ì¡°", "ê¸‰ì—¬", "ìˆ˜ë‹¹", "ì§€ì›ê¸ˆ", "ë³´ì¡°ê¸ˆ"],
    }
    
    expanded_terms = []
    query_lower = query.lower()
    
    for keyword, synonyms in KEYWORD_EXPANSION.items():
        if keyword in query_lower:
            expanded_terms.extend(synonyms)
        for synonym in synonyms:
            if synonym in query_lower and keyword not in expanded_terms:
                expanded_terms.append(keyword)
                expanded_terms.extend([s for s in synonyms if s != synonym])
    
    if expanded_terms:
        unique_terms = list(set(expanded_terms))
        expanded_query = f"{query} {' '.join(unique_terms[:5])}"
        return expanded_query
    
    return query

def search_documents(query, texts, metas, top_k=5):
    """ë¬¸ì„œ ê²€ìƒ‰ í…ŒìŠ¤íŠ¸"""
    expanded_query = expand_query(query)
    print(f"ğŸ” ì›ë³¸ ì¿¼ë¦¬: {query}")
    print(f"ğŸ” í™•ì¥ëœ ì¿¼ë¦¬: {expanded_query}")
    
    scores = []
    keywords = expanded_query.lower().split()
    
    for i, text in enumerate(texts):
        score = 0
        text_lower = text.lower()
        for keyword in keywords:
            if keyword in text_lower:
                score += text_lower.count(keyword)
        
        if score > 0:
            scores.append({
                "rank": i + 1,
                "score": score,
                "text": text,
                "source": metas[i]["source"],
                "chunk_id": metas[i]["chunk_id"]
            })
    
    # ì ìˆ˜ìˆœ ì •ë ¬
    scores.sort(key=lambda x: x["score"], reverse=True)
    return scores[:top_k]

if __name__ == "__main__":
    print("ğŸš€ Search Debug ì‹œì‘")
    
    # ë¬¸ì„œ ë¡œë“œ í…ŒìŠ¤íŠ¸
    texts, metas = load_documents()
    
    if not texts:
        print("âŒ ë¬¸ì„œê°€ ë¡œë“œë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
        exit(1)
    
    # ê²€ìƒ‰ í…ŒìŠ¤íŠ¸
    test_queries = [
        "ë‹¤ìë…€ê°€ì • í˜œíƒ",
        "ìë…€ ì§€ì›",
        "ì„ì‹  ì§€ì›",
        "ë³µì§€ í˜œíƒ"
    ]
    
    for query in test_queries:
        print(f"\n{'='*50}")
        print(f"ğŸ” '{query}' ê²€ìƒ‰ ê²°ê³¼:")
        results = search_documents(query, texts, metas)
        
        if results:
            for i, result in enumerate(results):
                print(f"\n{i+1}. ì ìˆ˜: {result['score']}")
                print(f"   ì¶œì²˜: {result['source']}#{result['chunk_id']}")
                print(f"   ë‚´ìš©: {result['text'][:200]}...")
        else:
            print("   ê²€ìƒ‰ ê²°ê³¼ ì—†ìŒ")
    
    print(f"\nğŸ”¥ Debug ì™„ë£Œ")


